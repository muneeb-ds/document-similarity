{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy scikit-learn PyMuPDF gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import fitz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from all PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(fname):\n",
    "    with fitz.open(fname) as doc:  # open document\n",
    "        text = chr(12).join([page.get_text() for page in doc])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs_recursively(dir):\n",
    "    raw_docs = {}\n",
    "    i = 1\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            raw_docs[f\"Doc{i}\"] = {}\n",
    "            path_to_pdf = os.path.join(root, file)\n",
    "            [stem, ext] = os.path.splitext(path_to_pdf)\n",
    "            if ext == '.pdf':\n",
    "                # print(\"Processing \" + path_to_pdf)\n",
    "                raw_docs[f\"Doc{i}\"]['category'] = stem.split(\"/\")[1]\n",
    "                raw_docs[f\"Doc{i}\"]['path']= path_to_pdf\n",
    "                raw_docs[f\"Doc{i}\"]['content'] = extract_text(path_to_pdf)\n",
    "                i += 1\n",
    "    return raw_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs = extract_text_from_pdfs_recursively(\"research_papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create collection of all docs and append to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = [doc['content'] for doc in list(raw_docs.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit TfidfVectorizer on Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of TfidfVectorizer arguments\n",
    "- **ngram_range = (1,2)** --> to include both unigram and bigram\n",
    "- **max_df = 0.8** --> Ignore terms that are in more than 80% of the docs i.e. most frequent terms such as stop words\n",
    "- **sublinear_td** = True --> Replace TF with 1 + Log(Tf)\n",
    "- **strip_accents** = 'unicode' --> character normalization\n",
    "\n",
    "Default Values:\n",
    "- lowercase = True\n",
    "- norm = 'l2'\n",
    "- use_idf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range= (1,2), max_df=0.8, sublinear_tf=True, strip_accents='unicode')\n",
    "tfidf = vectorizer.fit_transform(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_table = pd.DataFrame(tfidf.T.toarray(), columns=raw_docs.keys(), index=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf Table of (Vocabulary, Docs) size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "      <th>...</th>\n",
       "      <th>Doc41</th>\n",
       "      <th>Doc42</th>\n",
       "      <th>Doc43</th>\n",
       "      <th>Doc44</th>\n",
       "      <th>Doc45</th>\n",
       "      <th>Doc46</th>\n",
       "      <th>Doc47</th>\n",
       "      <th>Doc48</th>\n",
       "      <th>Doc49</th>\n",
       "      <th>Doc50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00 00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00 000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00 01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00 018</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ωωl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ωωl 2dω</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ωωl ηω2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ωωll</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ωωll mm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267256 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Doc1  Doc2      Doc3      Doc4      Doc5  Doc6  Doc7  Doc8  Doc9  \\\n",
       "00       0.005916   0.0  0.012193  0.004116  0.020069   0.0   0.0   0.0   0.0   \n",
       "00 00    0.000000   0.0  0.000000  0.000000  0.035909   0.0   0.0   0.0   0.0   \n",
       "00 000   0.000000   0.0  0.000000  0.000000  0.037150   0.0   0.0   0.0   0.0   \n",
       "00 01    0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "00 018   0.000000   0.0  0.000000  0.000000  0.008892   0.0   0.0   0.0   0.0   \n",
       "...           ...   ...       ...       ...       ...   ...   ...   ...   ...   \n",
       "ωωl      0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "ωωl 2dω  0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "ωωl ηω2  0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "ωωll     0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "ωωll mm  0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   \n",
       "\n",
       "            Doc10  ...  Doc41  Doc42  Doc43  Doc44  Doc45  Doc46  Doc47  \\\n",
       "00       0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "00 00    0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "00 000   0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "00 01    0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "00 018   0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...           ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "ωωl      0.018579  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ωωl 2dω  0.010973  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ωωl ηω2  0.010973  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ωωll     0.010973  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "ωωll mm  0.010973  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         Doc48     Doc49  Doc50  \n",
       "00         0.0  0.006702    0.0  \n",
       "00 00      0.0  0.000000    0.0  \n",
       "00 000     0.0  0.000000    0.0  \n",
       "00 01      0.0  0.000000    0.0  \n",
       "00 018     0.0  0.000000    0.0  \n",
       "...        ...       ...    ...  \n",
       "ωωl        0.0  0.000000    0.0  \n",
       "ωωl 2dω    0.0  0.000000    0.0  \n",
       "ωωl ηω2    0.0  0.000000    0.0  \n",
       "ωωll       0.0  0.000000    0.0  \n",
       "ωωll mm    0.0  0.000000    0.0  \n",
       "\n",
       "[267256 rows x 50 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace path with file of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = extract_text(\"test_doc.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = vectorizer.transform([doc]).T.toarray().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing dot product with each doc tfidf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "for docs in tfidf_table.columns:\n",
    "    raw_docs[docs]['test_similarity'] = np.dot(test_transformed, tfidf_table[docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with ranked values of test similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_docs_info = pd.DataFrame.from_dict(raw_docs, orient='index')[['category','path', 'test_similarity']]\n",
    "raw_docs_info['rank'] = raw_docs_info['test_similarity'].rank(ascending=False)\n",
    "raw_docs_info.sort_values(\"rank\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying top 10 most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>path</th>\n",
       "      <th>test_similarity</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc24</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.04649.pdf</td>\n",
       "      <td>0.222597</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc27</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.05589.pdf</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc30</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2311.16588.pdf</td>\n",
       "      <td>0.128944</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc26</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.03736.pdf</td>\n",
       "      <td>0.122977</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc25</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.15020.pdf</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc29</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.10432.pdf</td>\n",
       "      <td>0.103217</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc22</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2311.16965.pdf</td>\n",
       "      <td>0.092861</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc28</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2311.17354.pdf</td>\n",
       "      <td>0.092160</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc21</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.04944.pdf</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc23</th>\n",
       "      <td>nlp</td>\n",
       "      <td>research_papers/nlp/2312.01221.pdf</td>\n",
       "      <td>0.084308</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                path  test_similarity  rank\n",
       "Doc24      nlp  research_papers/nlp/2312.04649.pdf         0.222597   1.0\n",
       "Doc27      nlp  research_papers/nlp/2312.05589.pdf         0.130769   2.0\n",
       "Doc30      nlp  research_papers/nlp/2311.16588.pdf         0.128944   3.0\n",
       "Doc26      nlp  research_papers/nlp/2312.03736.pdf         0.122977   4.0\n",
       "Doc25      nlp  research_papers/nlp/2312.15020.pdf         0.106022   5.0\n",
       "Doc29      nlp  research_papers/nlp/2312.10432.pdf         0.103217   6.0\n",
       "Doc22      nlp  research_papers/nlp/2311.16965.pdf         0.092861   7.0\n",
       "Doc28      nlp  research_papers/nlp/2311.17354.pdf         0.092160   8.0\n",
       "Doc21      nlp  research_papers/nlp/2312.04944.pdf         0.089988   9.0\n",
       "Doc23      nlp  research_papers/nlp/2312.01221.pdf         0.084308  10.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs_info[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on highest cosine similarity the category of the Document is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs_info['category'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
